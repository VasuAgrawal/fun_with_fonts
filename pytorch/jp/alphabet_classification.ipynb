{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f83bc02bbd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "Batch shape: torch.Size([200, 1, 50, 50])\n",
      "Labels: tensor([ 4, 25,  3, 23,  0, 10, 24, 24,  0, 12, 17,  3,  8, 19, 15,  4, 23,  4,\n",
      "        14,  2, 13,  8, 24,  6,  3, 12, 19, 24, 10,  0,  3, 14,  0,  2, 13,  4,\n",
      "        15, 17, 24, 20,  4, 20,  4, 10,  6, 17,  0, 16,  2,  0, 13, 10,  1,  9,\n",
      "         4, 15,  1, 21,  6,  1,  8, 15, 12,  0,  5,  7, 16, 16, 12, 12,  6, 24,\n",
      "         7, 11, 24, 12,  4,  6,  2, 20,  2, 13,  9,  2,  2,  9,  2,  7,  4,  8,\n",
      "        14,  4,  1,  4, 25,  3, 19,  7, 22, 23,  5,  0,  5, 22,  1, 15, 24,  8,\n",
      "        14,  4,  9, 20, 16,  8, 21, 22,  4, 24, 18, 17, 23, 16,  6,  5, 16, 17,\n",
      "        11,  6,  3,  6, 17, 25, 25, 13,  4,  6, 13,  6,  8,  4,  1, 25,  7, 18,\n",
      "         5,  7, 17, 18, 17, 15, 13, 23,  7, 23,  5, 23, 25, 24,  1,  2,  1, 17,\n",
      "        25,  6,  2, 15, 10,  2, 12, 24, 14, 14,  4, 12,  9, 12,  1,  2, 22, 18,\n",
      "         5, 14, 14, 21, 22,  7,  4, 17, 10,  9,  9, 19, 25, 17,  0,  2, 12,  2,\n",
      "         6, 14])\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "\n",
    "def monoImageLoader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = PIL.Image.open(f)\n",
    "        return img.convert(\"L\")\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root = '/data/datasets/fonts/rendered/alphabet_upper_split_05/train',\n",
    "    loader = monoImageLoader,\n",
    "    transform = transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=200, shuffle=True,num_workers=10\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root = '/data/datasets/fonts/rendered/alphabet_upper_split_05/test',\n",
    "    loader = monoImageLoader,\n",
    "    transform = transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=5000, shuffle=False,num_workers=10\n",
    ")\n",
    "\n",
    "assert(train_dataset.classes == test_dataset.classes)\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "test_iter = iter(test_loader)\n",
    "train_images, train_labels = train_iter.next()\n",
    "print(\"Batch shape:\", train_images.size())\n",
    "print(\"Labels:\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABOCAYAAAA5Hk1WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnFUlEQVR4nO2deVxU1f//n4eZYREQUEFEUBYRxAUUM9c0yzW3T2raRysr85Et38z6aGKmUpiV9cklNUvT+llpm/mpD5paaZb7muYGKCIJiIiyyDLM+f3BMDEyAwiz8ek+H495MHPunXtfnLn3fc857/d5HyGlREFBQUGh4eFkbwEKCgoKCnVDMeAKCgoKDRTFgCsoKCg0UBQDrqCgoNBAUQy4goKCQgNFMeAKCgoKDZR6GXAhxGAhxBkhRJIQ4iVLiVJQUFBQqBlR1zhwIYQKOAsMAC4BB4AHpZR/WE6egoKCgoI56tMC7wYkSSlTpJQlwOfASMvIUlBQUFCoifoY8JZAWqXPl/RlCgoKCgo2QG3tEwghpgBTADQaTayPjw8lJSXWPm2dUalUODs7U1xcjE6ns7ccszg7O6NSqbh586a9pVSLm5sbZWVlDeI3LykpoayszN5yzKL85pajof3mly9fzpZS+lbZQUpZpxfQA9ha6fMsYFZ132nRooUcPny4BBz2FRERIefOnStbt25tdy3VvR544AE5a9Ysu+uo7iWEkLNnz5ajRo2yu5bqXm3atJFz586VISEhdtdS3Wv06NEyLi5OCiHsrqW6V1xcnBwzZozddVT3Cg4OlnPnzpXh4eF211Lda+TIkXLu3LkSOGjKptZnCOUAEC6ECBFCOAPjgc31OJ6CgoKCwm1Q5yEUKaVWCPEMsBVQAWuklCctpux/gISEBJ555pl6HSMzM5OZM2fyzTffWEiVgoLC/wr1GgOXUv4X+K+FtNQJIQRCCHQ6HUIIPDw8aNy4MV5eXnh5eeHi4kJqaiqpqak2HdP28/NjwoQJeHp6IoSo0zG0Wi27du1iy5YtFlanoOA4uLi40KNHD9Rq0+bo2LFjXLlypdpjCCEICQkhJCTE6H6TUnLw4EGuX79eaz3NmzfHx8en1vtXoNVq+fPPPyksLDS5XaPR0KJFCxo1amT2GFJKUlJSKC0trdU5re7EtCZubm6MHDmSVq1aceXKFfz8/AgKCiIwMNDw8vLy4rPPPmPGjBlkZ2fbTNuYMWPw8/Ors/EGSE5O5s0337xtp1VMTAyDBg0ye0OYQkqJVqvl5s2b5ObmkpGRwfnz50lJSXFoZ65CzajVanr37k2vXr1q3Fen0/Hhhx9y5coVevbsSe/evdFoNGb3LywsZOnSpWi12jrr8/LyYtmyZbRv377KNiklzz//PIsXL672GP7+/ixYsIDRo0cbXfd79uxhwoQJt2XAJ0yYwLhx42r/D+jJyspi7ty5HD582OR2X19f4uLi6Ny5s9ljFBUVMWHCBC5dulSrczZoAx4eHs7bb79Ns2bNKCgowMPDw+TFNnjwYJYuXWozA960aVOGDx+Oi4tLnY9RWlrKggULOHv27G1/NycnhxMnTuDk5ETbtm1ZtGhRlX22bdvG6tWrDa0FIQQajQZvb2/CwsIYPXo0zZo1Izk5mc2bN7N9+/bbugkUHAcPDw8eeughHnvssRr3LSgo4P3330cIwf33389zzz1ntiEgpWT//v2899579dKXn5/P1q1bTRpwgOHDh1drwNVqNSNHjmTIkCFGWtPS0li4cCGpqam3pefUqVMcOXKEnj17EhUVhUqlqnb/06dPk5iYyMWLF7l69arZ/QoLC/ntt9+4evUqnTt3ZsCAAajVaqSU5ObmsnnzZs6dO0dBQUGttTZYAy6E4IEHHqBFixYIIXB2dja7b/PmzenatSvHjh2zSWuye/futG3btsZukFqtNnlxSCnZuHEjmzfXzSd88eJFLl68CEC3bt1M7pOWlkZiYiI3btwwlAkhUKlUuLi44O7uzn333UdCQgIjRozg+PHjxMfHs3Pnznq1tsxR8RsKISpHOhm2VfRkSktLzYZ93XodVByj4rs6na7WXdP/JW7cuMG//vUvEhIS6NKlC8uXL8fXtzwiTUpJaWkpW7ZsYenSpZw5c4acnBwAXnvtNRYvXszAgQNZtmwZrq6uaLVaUlJSWL16Ndu2bePSpUv1DhcsLCxk586dTJkyBQ8PjyrbO3ToQEhICOfPnzf5/ZCQEOLi4mjcuLHhfyoqKmLNmjVs27bttu/5bdu2sWvXLpo3b85bb73FiBEjUKlUZnvTL7/8MomJiWi12mqvr9zcXD777DNUKhXt27enbdu2hIWFUVJSwowZM9iwYQMlJSW3VZ8N1oBrNBpGjx5d4xCFTqejoKCAoqIiGykrfyI/88wz1WpTq9VMnTqVQYMGVRmzO3v2LEuWLCE3N9cGav+iYhhFq9VSUFDA2rVrOXfuHOvWraNPnz58//33LFq0iCVLlpCVlWXRc7ds2ZLly5fTqVMnCgsLuXHjBkVFRahUKho3boynpydOTk7Mnj2b9evXmzyGn58f69atw8/PD61WS2FhIUII3NzcUKvVbN26lXnz5lFcXGxR7Y6OTqcjJyeHnJwcUlNT6du3r5FzfceOHTz88MNVeli5ubnk5uZy6tQpSkpKKCoq4uOPP2bu3LkWvzbPnTvH77//To8ePYzKhRC4u7tz9913mzTgjRo14q233iIwMNDo/92xYwfvv/9+nWLmK+6BlJQUnn/+ecLCwujUqZPZ/bt27co333xTqwdFRQOkU6dOtG7dGq1Wy9q1a1mzZk2dGpcN1oC3b9+ekJAQozIpJQUFBeTk5JCdnU1WVhZ//vknJ06cIDEx0WZjucnJySQnJ1e7z1133WVyLCw/P5+1a9dy/Phxa8mrNVJKDhw4wIoVK5g/fz6NGjVi+vTpBAQEEB8fz4ULFyx2royMDN544w2GDBnCxIkTadeuHVB+M546dYp169aRlJTE9u3bzR4jMzOTOXPm8OCDD/Loo4/i7e2NVqvl0KFDrF+/nu+++86mk0s6duxIWVkZf/zhWOmBvLy8DO/Lysp45513zA6PRUdHk5CQQFFREYsXL2bZsmVGvTZLcfHiRY4cOUK3bt2q9EpdXV3p06cPH3/8sVHvT6VS8dBDDzFw4EBDI0hKyYULF0hISODy5csW0fXKK6+wdu1as47NRx99lK+//poDBw7U6pgdO3bk5ZdfRqVSsXPnThYsWFBn29RgDfg999xj9ENLKVmxYgW7du3i2rVrBgOenZ1t09Z3bQgICGD69Ok0a9bMqPWt0+nYt28f69evdxjNxcXF7N69m5SUFDp06ICbmxsPPPAARUVFzJ49m2vXrlnkPFqtll9//ZWDBw+SlZXFvHnz8PHxQUrJvn37ePXVV2t1kR84cIDS0lL69++Pl5cX27dvJy4ujuPHj9t0xp1Go+GZZ55Bq9Xy9NNP2+y8NeHk5ETXrl0NnzMyMti7d6/Jfe+44w4WLlxIdHQ0CxYsYPXq1VYx3lA+9r5//37GjRtH06ZNjbapVCoiIyNp1aoVKSkphvLY2FimTp2Kq6uroay4uJgFCxaY/Z/qwpYtW1i1ahUvvPCCSX9AhXPyySefJDMzs9pj+fn58eqrrxISEkJKSgqLFi0iPT29ztoabD7wvn374uT0l/z8/HwWLFjAhg0b+OGHHzh8+DCXLl1yGENYgVqtZsyYMdx9991VWhoFBQUsXLiQtLQ0M9+2D2fOnCEpKckwpuzu7s7DDz/M2LFj6xVlY4ri4mI2btzIjz/+WD7TzMmJNm3aEBwcXKvvCyEICAjA39+fxMREnnrqKY4cOWLz6dIRERHExsYyePDg24oGsjYRERFGPdcff/zR5DBDdHQ0b7zxBj179mTevHmsWLHCYg9rc+zdu5fLly8b+T+g/DcNDAw0cnI2adKExx9/nKioKKPW90cffcQXX3xhUV0lJSV8+OGH/Pzzz1W0Vejr378/EydOrPa31mg0PP3009xzzz0UFBTw8ccfs2PHjnpdmw3SgAcGBhIaGmpkPHbs2FFjrKgjEBMTw5QpU/D09DQqLysrY+XKlfz44492Umaea9eucfLkSaOxY3d3d+bPn4+/v7/Fz5eRkcHq1asND7KuXbsyatSoah3VFURGRhIfH8+vv/7K008/bdbxZU2EENx5552EhYXRvHlzYmNjba7BHMOHDzdEaul0Or799tsqPZuoqCiWLVtG586dmTlzJsuXL7+tyIi6cvbsWbOBBv7+/kRHR6NWq3FycmLQoEGMHz/e6H/55ZdfWLx4MXl5eRbXlpSUxNKlS0lLSzP5gPH09GTy5Mn07NnTZKPGycmJ4cOH89hjj+Hq6spPP/3E4sWL693AbJAGvEOHDnh5eRk9ebdu3WqV6AhL4uHhwVNPPUX79u2r/MiHDx/mnXfeMfmEdwTOnDlTZYKCn58fTz75pFXOt337dv7zn/+g0+lo1KgRkyZNomPHjtV+JzIykvfee4/k5GRmzZpl0TH626FZs2b4+/uTlZWFWq2mf//+dtFxKy4uLgwcONDQc7148SLHjh0zuuY6duzIqlWrCA8PJz4+ng8//NBm95WUks2bN5v0U6jVamJiYvD19SU0NJSZM2caRZ2kp6ezePHiOoXd1patW7eyfv16k05wIQSRkZE8++yzNGvWrMr2yMhIpk2bRmBgIElJScycOdMiYbkN0oC3b9/eyBGTm5vLoUOHHH7CyYgRI0xOEMjMzOTtt9926B5ESkpKla62EIJhw4bRpEkTi5+vtLSUd955xzDm2aFDB6ZOnWq2FR4VFcWbb77JpUuXiIuLs+qNXBPBwcF4eHiwfft2dDodvXr1qtecAEvRrl07o57rb7/9ZjQscuedd/Luu+/Stm1bFi5caDRPwFbs2LHDbCx1586dadWqFTNmzCA6OtpQXlxczNq1a9myZYtVG0DFxcW899577Nmzx+x5hg8fziOPPGJU5ubmxosvvkjPnj3Jyclh3rx5nDp1yiKaGpwBd3Z2Jjw83Gg66okTJ2p0HtibkJAQZs+ejZubm1G5Vqvl22+/5YcffnDotJaZmZlVWkZCCPz9/asNsaoPKSkpvPXWW4Y0CePGjWPgwIFV9mvdujVz5swhMzOT2bNn1xgBZE3UajXdu3fn6tWr/PLLL5SWlhIcHExYWJjdNFXQq1cvvL29gfLrbs+ePYZWYGxsLAsXLqRbt27MmTOHDz/80GoOy+q4evWq2UijCuNduREkpWTXrl0sXrzYJg+b9PR04uLizPoDXFxceP7557nzzjsNZY8//jjjxo1Dp9OxevVq/vOf/1hMT4Mz4M2bN6dVq1ZGDszs7GzatWvHnDlzSExMJCkpiUuXLrFx48ZaO7+siYuLCy+99BLh4eFVYr5Pnz7NqlWrrO4gqi9XrlwxOUnB3d3dEPJnDTZt2kRiYiJSStzd3Zk3b57BCEG5M2v27Nnk5+czb948uzuAGzVqxL333svRo0c5duwYxcXF+Pr6EhMTY1ddrq6u3HnnnYaJMmlpafzxxx+UlZURGRnJkiVL6Nq1K//617/46KOPyM/Pt5vWzz//3GRvWq1WM2LECIP/SErJ5cuXee6556qdAWlpDh48yGuvvWZ20o6/vz8JCQn4+vrSu3dvZsyYYRj3XrVqlUXrtsEZ8BYtWhAUFGRUNmrUKBITE5k/fz6DBg0iNDSUgIAAhg0bxsMPP2wnpeWoVCpGjRrFsGHDqniob968yQcffMChQ4fspK725OfnU1ZWVqXr6OLiQkBAgNXOm52dzXvvvUdGRgZCCNq1a8eUKVNQq9V4e3sTFxeHs7Mz8+bNq1c4lqXo3r07TZs25ejRoyQlJZGbm0uTJk0MDjh70aZNG9q2bWuY6Xr27FnOnTtHVFQUn3zyCT169ODChQts377d7gsxHDp0iKSkJJPb1Gq1oRF0/fp14uLiOHfunC3lodVq+fzzz9m0aZNJ/0CFE3v+/PnMnz+fli1bcuHCBf7973+b/b/qSoM04JVnXcFfU61NvewdwhUcHMzjjz9umPJfmR07drBmzRo7Kbs9ysrKTLY41Gp1lYgaSyKlZO/evWzatImSkhLc3NwYP348gwYNYvr06bi5uREXF+cQxlsIwaRJkzh8+DDZ2dmUlpZy/PhxVCoV7dq1o3nz5nbTFh4eTlhYGEIISktLOXnyJEFBQaxcuZLY2FiDE67ivT0pKCioMQNnUVGRYXKWPYYeL1++zPLly43CayuoyIr6xBNP0LdvX0pLS1m+fDnbtm2zuI4GZcA1Gg2hoaEG73NNFBUVcfr0aSurMo+zszMTJ06kT58+VW6K9PR04uPj7dpVvV3MOW6sfcNfu3aNtWvXGpISRUVF8cYbb6DRaIiPj+fPP/+06vlrS2RkJN26deOHH34wlFXMzouMjKzS8LAVrq6uREdHG5zNN27cQKvVkpCQgL+/v8F5rlareeihh2pM3mRtioqK2Llzp9l7Q0rJkSNHWLFihU2HTm5lz549rF692myIZUWuo6+++ooPPvjAKg+aBmXA3dzciIqKMhr/BgzJj3Q6HTqdjrKyMrRaLenp6dVOvbY2HTp04P/+7/+MZopBeRfs3XffdYjp8rXFycnJZKZHnU5nkzUaDx06xOrVq9Fqtbi4uBAUFMTPP/9s8Zws9WHUqFGG6dEVVBjw4ODgKnMXbIWPjw89evQw3Dfu7u6MHTuW8PBwpk2bxqZNmwwP57vvvpvQ0FCba6yMlJIzZ86YTUFw48YNEhISLBbJUVeKi4t5//332bVrl9nGTU5ODq+//rrVHMINyoC7u7sbRTzodDqysrI4ffo0u3fvZv369SxYsIAnn3ySoUOHMmjQILvd4J6enrz77rtV8ifodDq2bt3KF198YfexxtvB1dXVZEa2kpISm4Q/CiE4f/68YeKDp6cnzz33nFWHb24HPz8/Bg4cyC+//GI0keTYsWPcvHkTtVpNz549q0Qh2Upb5ayUrq6ueHh4MGfOHLZt28ann35quBZdXV2ZNGmSzTXeSkZGhsmxbSklv/76K99//71DhA3n5eXx3HPPmZ2QU5Ff31o0KAPeuHFjIiIiDJ+vX7/Oiy++SHR0NHfddRcPP/ywIQRq27ZtdhsX1Wg0TJ06lTvuuKNK1Mnly5dZvXr1becotjc+Pj4m/Qk3b960+mxHZ2dn7r33Xh599FE+/fRTrl+/jhCCQYMG1SnxvjXo3r07bdq0qZIC+ObNm5w6dQohBL169ap2NRZrIISgT58+hsgdKSX5+fksW7aML7/8ktLSUs6dO2dwpAshuO+++wzpZu2Fp6enyQkxUB4F4kj8+eefNpmpaooGZcAjIyONJvDk5eXx008/OVyO5+7duzNp0qQqkze0Wi1fffWVVZwZ1sbf39/kJJr8/Hx+//13q51XrVYzYMAApk6dyieffMJLL73El19+aYgNnz59Oh06dLDa+WuDu7s7vXv3RgjBvn37jLaVlZVx9OhRoHwiza0RVNZGpVIxfPhww2cpJevWrWP58uWGnkJOTo5h0lFF3pEBAwbYVOetNG3a1KzPoKI+FRqQARdC0L17d8NnKSUXL150GAdWBb6+vjz22GO0adOmynDD+fPnWbRoUYNyXFYQFBRUZSxfSskff/xh1RZ4nz59iIuLIzExka+//prr16/z0UcfGZzTYWFhPPvsszZv2VYmMDCQfv36sW/fvirdZa1Wy9GjR5FS4urqyt13321Tbb6+vkY5ttPT03nttdeMVqcqKipi3759ZGRkAOXpZgcOHGjXOm3SpIlJAy6lVAx4JRqUAb91dZm9e/c6xDhYBSqVioEDBzJ27NgqDr/i4mJmzpxp94kmdSUqKgp3d3ejMq1WWyVHs6VQqVT069eP999/n//+97+sWbOGoqIiwzJen3/+uWFsediwYQwZMsQuDkInJyeio6OJiYlh9+7dSClxdnZGo9GgUqmQUnLy5ElDL3Ho0KE21Tlo0CCDIZZS8sUXX5j0WZw4cYLff//dkAGyc+fOZpc4szYqlYrWrVubjDZLTU21a+SJo+E4eS5rwNnZ2SiZkZSS3bt321FRVUJCQpg1a5ZJQ7d+/Xqj8LKGREX0z60OuKNHj1p0WnAFLi4uDBgwgIULF/Ltt9/y1ltvGTl8S0tL+eSTT7j33nvp3bs3AQEBPPbYYxw4cMCwlJytcHFxYfz48Tg5OdGvXz/8/f25ceMG+fn55Ofnk5eXh7+/P7m5ufj5+REbG4uvr69NnOtOTk4MGzbMEH1SWFjIV199ZbLRk5aWxoEDB+jbty+urq60bduWO+64g8OHD9s8ztrZ2dkoTWxlTp486fBJ62xJgzHgYWFhRk9krVbrUM4MZ2dnZsyYYbLVkp2dzf79++nQoUONyXYKCgo4e/asQ12kbdu2JSIiwuiGys7O5vXXX7d4vnWNRsPQoUOZPXs2P//8M/Hx8SajdS5cuMCSJUuIjY3F3d2d/v37M2bMGJYsWWLTugsODqZ3794cO3YMrVZLUFAQxcXFFBcXU1RURHFxMRqNhitXruDn54erqyv9+vVj48aNVtcWFBRklPRp7969RgsiVEZKyY4dO5g0aRKBgYG4urpy77338uWXX9o8kqvCgJvixIkTDnVv2JsGY8A7depkFP9dUFBg1JWKiIhg5MiRhIeHs2nTJpunlx01ahRjx441uc3Dw4Pp06fXGDZYEWI4a9Ysa0isE05OTnTp0sUo+qeoqIiPPvqI7du3Wzz72+DBg3nttdfYt28fr7/+erW5nb///nu++eYbJk6ciKurK9OmTSMxMdGm8cEPPfQQV69eZebMmfzxxx+GhW1LS0sN7xs1aoRaraZ9+/ZoNBr69+9vEwPeo0cPfHx8EEKg0+nYvn27YcFiU+zfv5+UlBRatmyJEIK+ffvSunVruxhwc/l1HLUFbm5YzMnJyapDZg3GgLdv397IgLu5udGuXTs0Gg2TJ09m8ODBNG3aFGdnZzp16sTp06dtlpUuLCyMadOmGUXIVMbDw4O2bdvWeJzCwkLi4+MdKithy5YtmTBhAh4eHoYVzL/55hveffddiybOd3JyYuDAgaxcuZKjR48SHx9fYxhoUVERCQkJ3HPPPYYUC6+++irjx4+3yU3etm1bHnzwQb744gt++ukns79bXl4eZ8+epaioCBcXF2JiYmjSpEm1xrS+CCHo0aOHodd67do1w+LE5igsLGTTpk306tULlUqFj48Po0aNsnmqZl9fX1q2bFml/MaNG6SmpjqU3wvKbZG5e9/b27tWC5HUlQbjxIyMjDR6krm4uHDw4EH27NnD5MmTCQwMNLR0bg03tCbu7u488cQTdOnSpd5P2rNnz1plTLkuqNVqgoODSUhIMCxIkJ2dzbp163j22WctGv3j7u7OuHHj+OCDD3B1dWXlypW1Xozh4sWLbNiwAcAQGz5lypQqfghL4+bmxgsvvIBGo2H58uU1PnSTk5PJyspCCEHz5s2tnp0wNDSUmJgYQ+x+xQrzNbFlyxbD/yKE4IEHHqh16gpLERsba3I6f2pqqkNl7axYiWfMmDFm0w+4uroyfPhwGjdubJWWeINogQshDN26ymXmKuTatWsmV82wNE5OTvTp04dx48bVO2G/Tqdj+fLldpudqVKpcHV1NcTfxsTE8OCDD9KjRw8yMjI4evQon332GRs2bLCYRpVKRceOHfnHP/7B5MmTCQgIID8/nzvuuINz586RnJxsMsZfpVLh5+eHv78/AQEBRq01d3d34uLiaNWqFbt27SI5OZm0tDSL5op2cXFh9OjRDBkyhLS0tFpFFp0/f57MzExatWpFs2bNiI6OttryeR4eHgwdOtRo5acmTZrQvn17Dh8+bLbnpNFocHd3N7qvQkNDmTp1KmvXriUzM9Mmrd8uXbqYLL948aJFVrGpL2q1mpEjR9KkSROioqL45z//aXZfIQSvvPIKYWFhHD9+nOzsbLZu3Wqx67FBGHCAS5cu0a1bN7NGW0pJYWEhKSkpHDp0yCY/tJeXF9OmTaN169b1Pta5c+dITEy0gKry2Ol//vOfqNVq/Pz8TO7Tq1cvli5dSklJCUIIQ64TV1dXPD09adSoEZmZmcTHx3Po0CGOHz9Oenq6RW/gAQMG8PLLL9O6dWsKCws5deoUjRo1YuLEifTq1YtFixaZXGUlICCAF198kW7duuHp6Ym3tzcXL140OA+FENx///0MGDCA7OxstmzZwpIlSywyNBUREcHjjz/OiBEjaNmyJW5ubsydO5edO3fy22+/mc0LUzFnoSKvefv27fH09LTYMJRKpeL+++8nNjaWoKAgevToYbS6u7e3N88//zx33XUXWVlZbNy40RDF1aJFC1555RXc3NyIiIgwak0KIZgxYwa9evUiKyuLffv28cEHH1jVkJsz4KmpqQ5hwF1cXHjnnXcICAgwmV7iVnx8fHj66acpKyvjwoULHDhw4O9lwKWUvPDCC+Tl5fHggw8ipSQnJ4e0tDSSk5M5c+YMp06d4uzZs4bwLVvEiubl5TF9+nSTSZ5ul4KCAosNS5w8eZIVK1YYLqxXXnmlVt+TUhrSxpaUlFBYWMiNGzcsHmlSwaFDh5g6darB2SelRKVSGbK4mVqhHCArK4ulS5fSqFEjysrKDAnMKpKZAUbHycvLs5jBSU9PZ82aNaxfv95QVlRUxNWrV6vt9VU8oAYPHoyLiwuRkZG0bNnSYtkyW7RowSOPPMI999yDRqMxOC4rExoaSmhoKBkZGXz33XeG8ujoaCZPnmzkY6r83caNGzNkyBCgvCFl7Tj2KVOmVJk0BuWLilhjweLb5ebNm9x33311ytpYWlpq0dXDGoQBh/IWzJQpU3jqqacA4wyElf/aEq1WazZjmj3JycmxqoPMUly5cqVOibCKi4stnhi/tuTn59fZ6O7fv5+bN2/i7OxMREQEwcHBFjPg6enp3H///VUydZqiwhldwQ8//FDrpGBardbqTvYzZ85Y9fj1RafTceLECXvLABqQAYfyi8cRQ4gUFGrDzp07uXz5Ml5eXjRr1oyhQ4eye/dui6RWkFLW2Teh0+ms1stSsC61ikIRQlwQQvwuhDgqhDioL2sihNgmhDin/+tT03EUFP6uODk5IaU0GtqbMGECkyZNws/Pr1YtZwWFW7mdq+ZuKWWMlLKr/vNLwA4pZTiwQ/9ZQUHhFpo0acLcuXP57rvvjMIHK8rXrl1Lnz597CdQocFSnyGUkUA//ft1wM/AzHrqUVD4nyM3N5e3336bpUuXmtyu0+kaZIZKBftTWwMugR+EEBJ4X0q5Cmgupbys354B2G/FVgUFB0an01ltSS2Fvze1NeC9pZTpQgg/YJsQwsh1LqWUeuNeBSHEFGAKYLPZkQoKCgp/B8Ttht4JIeYB+cATQD8p5WUhRAvgZyllRHXfDQgIkGPHjrXbUme1oXHjxrRq1Yrz58/bbZmk2tCqVSs8PDwcMoyxAiEEUVFRXL9+nUuXLtlbjlk8PT1p3bo1Fy5ccOihjKCgIDw9PTl16pTNQ2Zvh6ioKPLy8hw69727uzshISGkpqY6RGy5OQIDA/H29mb+/PmHKvkfDdTYAhdCuANOUso8/fuBQDywGXgEWKj/+21tBPn4+FRZ6NcRCQkJsbeEWmHv5cRqg7e3t2FNRkcmODjY3hJqhb0WWrgdvLy8GkSP2xKzqO1JjS1wIUQo8I3+oxr4VEqZIIRoCmwEWgGpwANSympnjwgh8gBHjtJvBmTXuJf9UPTVD0Vf/XF0jf+r+lpLKausNH3bQyj1QQhx0FQ3wFFQ9NUPRV/9cHR94Pga/276lNkDCgoKCg0UxYArKCgoNFBsbcBX2fh8t4uir34o+uqHo+sDx9f4t9Jn0zFwBQUFBQXLoQyhKCgoKDRQbGbAhRCDhRBnhBBJQgiHSHzlaFkWhRBrhBBZQogTlcpM6hHlLNHX53EhhOllTKyvb54QIl1fh0eFEEMrbZul13dGCDHIBvqChBA/CSH+EEKcFEI8py93iDqsRp9D1KEQwlUIsV8IcUyvb76+PEQIsU+vY4MQwllf7qL/nKTfHmwnfWuFEOcr1V+Mvtzm94j+vCohxBEhxHf6z9arv4qFEaz5AlRAMhAKOAPHgChbnLsGXReAZreUvQm8pH//EvCGDfXcBXQBTtSkBxgKJAIC6A7ss5O+ecCLJvaN0v/OLkCI/vdXWVlfC6CL/r0ncFavwyHqsBp9DlGH+nrw0L/XAPv09bIRGK8vXwlM1b9/Clipfz8e2GDl+jOnby0wxsT+Nr9H9OedDnwKfKf/bLX6s1ULvBuQJKVMkVKWAJ9Tns3QERlJeXZF9H9H2erEUspdwK2ToczpGQl8LMvZC3iL8pQGttZnjpHA51LKYinleSCJ8uvAakgpL0spD+vf5wGngJY4SB1Wo88cNq1DfT1U5BLQ6F8S6A98qS+/tf4q6vVL4B4hrLfeWjX6zGHze0QIEQjcB3yo/yywYv3ZyoC3BConRrhE9ReurajIsnhIlCfdAsfLsmhOjyPV6TP6LuqaSkNOdtWn7452pryV5nB1eIs+cJA61Hf/jwJZwDbKW/25UsqKpbAqazDo02+/DjTFityqT0pZUX8J+vr7txDC5VZ9JrRbi3eBGUDFoqJNsWL9/d2dmL2llF2AIcDTQoi7Km+U5X0bhwnTcTQ9elYAYUAMcBl4265qACGEB/AVME1KaZTH1RHq0IQ+h6lDKWWZlDIGCKS8tR9pLy2muFWfEKIDMItynXcATbDTugRCiGFAlpTykK3OaSsDng4EVfocqC+zK1LKdP3fLMrzvXQDMiu6Wfq/WfZTCNXocYg6lVJm6m8qHfABf3Xx7aJPCKGh3Diul1J+rS92mDo0pc/R6lCvKRf4CehB+dBDReK7yhoM+vTbvYCr2IBK+gbrh6aklLIY+Aj71V8vYIQQ4gLlw8T9gcVYsf5sZcAPAOF6b6wz5QP2m210bpMIIdyFEJ4V7ynPsniCv7Iswm1kWbQi5vRsBh7We9q7A9crDRPYjFvGFP9BeR1W6Buv97SHAOHAfitrEcBq4JSU8p1KmxyiDs3pc5Q6FEL4CiG89e/dgAGUj9P/BIzR73Zr/VXU6xjgR30Px5b6Tld6OAvKx5cr15/Nfl8p5SwpZaCUMphyG/ejlHIC1qw/S3tgzb0o9wifpXxMbbatzluNnlDKPfzHgJMVmigfg9oBnAO2A01sqOkzyrvQpZSPlT1uTg/lnvX39PX5O9DVTvo+0Z//uP6CbFFp/9l6fWeAITbQ15vy4ZHjwFH9a6ij1GE1+hyiDoFOwBG9jhPAK5Xulf2UO1G/AFz05a76z0n67aF20vejvv5OAP+PvyJVbH6PVNLaj7+iUKxWf8pMTAUFBYUGyt/diamgoKDQYFEMuIKCgkIDRTHgCgoKCg0UxYArKCgoNFAUA66goKDQQFEMuIKCgkIDRTHgCgoKCg0UxYArKCgoNFD+PzAxqPrOYtxQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(train_images[:8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch output shape: torch.Size([200, 26])\n",
      "Parameters 0 torch.Size([6, 1, 3, 3])\n",
      "Parameters 1 torch.Size([6])\n",
      "Parameters 2 torch.Size([16, 6, 3, 3])\n",
      "Parameters 3 torch.Size([16])\n",
      "Parameters 4 torch.Size([16, 16, 3, 3])\n",
      "Parameters 5 torch.Size([16])\n",
      "Parameters 6 torch.Size([120, 256])\n",
      "Parameters 7 torch.Size([120])\n",
      "Parameters 8 torch.Size([84, 120])\n",
      "Parameters 9 torch.Size([84])\n",
      "Parameters 10 torch.Size([26, 84])\n",
      "Parameters 11 torch.Size([26])\n",
      "Trainable parameters: 46474\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, len(train_dataset.classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "n = net(train_images)\n",
    "print(\"Batch output shape:\", n.shape)\n",
    "\n",
    "for i, p in enumerate(net.parameters()):\n",
    "    print(\"Parameters\", i, p.size())\n",
    "print(\"Trainable parameters:\", sum([p.numel() for p in net.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step   200] train loss: 3.2512, accuracy: 0.035 (  7 / 200), test loss: 3.2537, accuracy: 0.038 (4558 / 120223)\n",
      "[Step   400] train loss: 3.2397, accuracy: 0.110 ( 22 / 200), test loss: 3.2449, accuracy: 0.085 (10239 / 120223)\n",
      "[Step   600] train loss: 3.2012, accuracy: 0.120 ( 24 / 200), test loss: 3.1977, accuracy: 0.124 (14883 / 120223)\n",
      "[Step   800] train loss: 1.1062, accuracy: 0.650 (130 / 200), test loss: 0.9392, accuracy: 0.725 (87221 / 120223)\n",
      "[Step  1000] train loss: 0.3713, accuracy: 0.875 (175 / 200), test loss: 0.4359, accuracy: 0.878 (105558 / 120223)\n",
      "[Step  1200] train loss: 0.2446, accuracy: 0.920 (184 / 200), test loss: 0.2903, accuracy: 0.922 (110791 / 120223)\n",
      "[Step  1400] train loss: 0.1670, accuracy: 0.960 (192 / 200), test loss: 0.2525, accuracy: 0.936 (112517 / 120223)\n",
      "[Step  1600] train loss: 0.2995, accuracy: 0.920 (184 / 200), test loss: 0.2062, accuracy: 0.948 (113942 / 120223)\n",
      "[Step  1800] train loss: 0.2031, accuracy: 0.940 (188 / 200), test loss: 0.1828, accuracy: 0.952 (114502 / 120223)\n",
      "[Step  2000] train loss: 0.2750, accuracy: 0.955 (191 / 200), test loss: 0.1608, accuracy: 0.958 (115208 / 120223)\n",
      "[Step  2200] train loss: 0.1982, accuracy: 0.945 (189 / 200), test loss: 0.2083, accuracy: 0.943 (113419 / 120223)\n",
      "[Step  2400] train loss: 0.1767, accuracy: 0.950 (190 / 200), test loss: 0.1319, accuracy: 0.965 (115986 / 120223)\n",
      "[Step  2600] train loss: 0.1368, accuracy: 0.950 (190 / 200), test loss: 0.1352, accuracy: 0.964 (115853 / 120223)\n",
      "[Step  2800] train loss: 0.0963, accuracy: 0.980 (196 / 200), test loss: 0.1166, accuracy: 0.969 (116545 / 120223)\n",
      "[Step  3000] train loss: 0.0680, accuracy: 0.960 (192 / 200), test loss: 0.1187, accuracy: 0.964 (115855 / 120223)\n",
      "[Step  3200] train loss: 0.0905, accuracy: 0.990 (198 / 200), test loss: 0.1005, accuracy: 0.974 (117130 / 120223)\n",
      "[Step  3400] train loss: 0.1521, accuracy: 0.955 (191 / 200), test loss: 0.0915, accuracy: 0.977 (117414 / 120223)\n",
      "[Step  3600] train loss: 0.0813, accuracy: 0.960 (192 / 200), test loss: 0.0917, accuracy: 0.977 (117461 / 120223)\n",
      "[Step  3800] train loss: 0.1077, accuracy: 0.970 (194 / 200), test loss: 0.0799, accuracy: 0.979 (117743 / 120223)\n",
      "[Step  4000] train loss: 0.0412, accuracy: 0.985 (197 / 200), test loss: 0.0794, accuracy: 0.980 (117799 / 120223)\n",
      "[Step  4200] train loss: 0.0603, accuracy: 0.990 (198 / 200), test loss: 0.0921, accuracy: 0.974 (117079 / 120223)\n",
      "[Step  4400] train loss: 0.0849, accuracy: 0.980 (196 / 200), test loss: 0.0740, accuracy: 0.982 (118021 / 120223)\n",
      "[Step  4600] train loss: 0.1211, accuracy: 0.975 (195 / 200), test loss: 0.0741, accuracy: 0.981 (117943 / 120223)\n",
      "[Step  4800] train loss: 0.1459, accuracy: 0.980 (196 / 200), test loss: 0.0715, accuracy: 0.982 (118019 / 120223)\n",
      "[Step  5000] train loss: 0.0508, accuracy: 0.990 (198 / 200), test loss: 0.0652, accuracy: 0.983 (118182 / 120223)\n",
      "[Step  5200] train loss: 0.0547, accuracy: 0.980 (196 / 200), test loss: 0.0630, accuracy: 0.984 (118342 / 120223)\n",
      "[Step  5400] train loss: 0.0767, accuracy: 0.980 (196 / 200), test loss: 0.0637, accuracy: 0.984 (118276 / 120223)\n",
      "[Step  5600] train loss: 0.0647, accuracy: 0.985 (197 / 200), test loss: 0.0620, accuracy: 0.985 (118361 / 120223)\n",
      "[Step  5800] train loss: 0.0298, accuracy: 0.990 (198 / 200), test loss: 0.0594, accuracy: 0.985 (118393 / 120223)\n",
      "[Step  6000] train loss: 0.0630, accuracy: 0.980 (196 / 200), test loss: 0.0607, accuracy: 0.985 (118408 / 120223)\n",
      "[Step  6200] train loss: 0.0286, accuracy: 0.995 (199 / 200), test loss: 0.0578, accuracy: 0.985 (118443 / 120223)\n",
      "[Step  6400] train loss: 0.0310, accuracy: 0.995 (199 / 200), test loss: 0.0536, accuracy: 0.987 (118605 / 120223)\n",
      "[Step  6600] train loss: 0.0410, accuracy: 0.990 (198 / 200), test loss: 0.0532, accuracy: 0.987 (118642 / 120223)\n",
      "[Step  6800] train loss: 0.0148, accuracy: 1.000 (200 / 200), test loss: 0.0537, accuracy: 0.986 (118516 / 120223)\n",
      "[Step  7000] train loss: 0.0693, accuracy: 0.980 (196 / 200), test loss: 0.0517, accuracy: 0.987 (118658 / 120223)\n",
      "[Step  7200] train loss: 0.0929, accuracy: 0.975 (195 / 200), test loss: 0.0507, accuracy: 0.987 (118651 / 120223)\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(comment=\"_alphabet\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(1):\n",
    "    \n",
    "    for train_minibatch, (train_inputs, train_labels) in enumerate(train_loader):\n",
    "        global_step += 1\n",
    "        \n",
    "        # Core training loop\n",
    "        train_inputs, train_labels = train_inputs.to(device), train_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_outputs = net(train_inputs)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", train_loss.item(), global_step)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute metrics for this particular minibatch\n",
    "            _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "            train_total = train_labels.size(0)\n",
    "            train_correct = (train_predicted == train_labels).sum().item()\n",
    "            train_accuracy = train_correct / train_total\n",
    "\n",
    "            writer.add_scalar(\"Accuracy/train\", train_accuracy, global_step)\n",
    "\n",
    "            if global_step % 200 == 0:\n",
    "                print(\"[Step {:5d}] train loss: {:0.4f}, accuracy: {:0.3f} ({:3d} / {:3d}), \".format(\n",
    "                    global_step, train_loss.item(), train_accuracy, train_correct, train_total\n",
    "                ), end = \"\")\n",
    "            \n",
    "                # Now run through the full test dataset\n",
    "                test_loss = 0\n",
    "                test_total = 0\n",
    "                test_correct = 0\n",
    "                for test_minibatch, (test_inputs, test_labels) in enumerate(test_loader):\n",
    "                    test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "\n",
    "                    test_outputs = net(test_inputs)\n",
    "                    test_loss += criterion(test_outputs, test_labels) * test_labels.size(0)\n",
    "\n",
    "                    _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "                    test_total += test_labels.size(0)\n",
    "                    test_correct += (test_predicted == test_labels).sum().item()\n",
    "\n",
    "                test_loss /= test_total\n",
    "                test_accuracy = test_correct / test_total\n",
    "\n",
    "                print(\"test loss: {:0.4f}, accuracy: {:0.3f} ({:3d} / {:3d})\".format(\n",
    "                    test_loss, test_accuracy, test_correct, test_total\n",
    "                ))\n",
    "                \n",
    "                writer.add_scalar(\"Loss/test\", test_loss.item(), global_step)\n",
    "                writer.add_scalar(\"Accuracy/test\", test_accuracy, global_step)\n",
    "                writer.add_images(\"Images/test\", test_inputs[:100], global_step)\n",
    "                writer.add_images(\"Images/train\", train_inputs[:100], global_step)\n",
    "\n",
    "            \n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"alphabet.pth\"\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
